# toy-transformer-sentiment

For theory of Transformers and Large Language Models (LLMs), see our [wiki](https://github.com/iffatAGheyas/transformer-experiments/wiki).


![image](https://github.com/user-attachments/assets/9e2577ba-35d3-4ba3-935b-3bc99f8e2145)


### Whatâ€™s Inside

- **`toy_transformer_sentiment/data/`**  
  Contains the Excel files for our small train (40 examples) and test (200 examples) splits.

- **`.ipynb_checkpoints/`**  
  Auto-generated by Jupyter; you can ignore or remove these as needed.

- **`fine_tune_toy_model.ipynb`**  
  Walks through subsampling SST-2, tokenisation, training a toy DistilBERT, and saving the model.

- **`inference_toy_model.ipynb`**  
  Interactive inference: feed your own sentences for classification by both the toy model and the official SST-2 checkpoint.

- **`README.md`**  
  Overview of the project and instructions for running the notebooks.

Feel free to clone, explore the notebooks, and adapt this pipeline for larger datasets and more extensive fine-tuning!  
