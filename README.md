# toy-transformer-sentiment

For theory of Transformers and Large Language Models (LLMs), see our [wiki](https://github.com/iffatAGheyas/transformer-experiments/wiki).

![image](https://github.com/user-attachments/assets/0ebfe88e-be21-49b5-83c3-9f4aaa3dbed9)



### Whatâ€™s Inside

- **`toy_transformer_sentiment/data/`**  
  Contains the Excel files for our small train (40 examples) and test (200 examples) splits.

- **`toy_transformer_sentiment/models/distilbert_finetuned/`**  
  The output directory holding the fine-tuned DistilBERT model and tokenizer files.

- **`.ipynb_checkpoints/`**  
  Auto-generated by Jupyter; you can ignore or remove these as needed.

- **`fine_tune_toy_model.ipynb`**  
  Walks through subsampling SST-2, tokenisation, training a toy DistilBERT, and saving the model.

- **`inference_toy_model.ipynb`**  
  Interactive inference: feed your own sentences for classification by both the toy model and the official SST-2 checkpoint.

- **`README.md`**  
  Overview of the project and instructions for running the notebooks.

Feel free to clone, explore the notebooks, and adapt this pipeline for larger datasets and more extensive fine-tuning!  
