{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "291c3b85-1ad0-47e4-a6ea-c6fe29c77b3a",
   "metadata": {},
   "source": [
    "# Sentiment Classification Demo Notebook\n",
    "\n",
    "Welcome to the inference notebook for our sentiment classification models. Below you‚Äôll find two sections:\n",
    "\n",
    "---\n",
    "\n",
    "## 1. Interactive Inference with Our Toy DistilBERT Model\n",
    "\n",
    "Use the cell below to classify your own sentences as **positive** or **negative**. Simply edit the `sentences` list at the top with the text you want to evaluate.\n",
    "\n",
    "> **Note:** This is a **toy model** trained on only 40 examples due to limited compute resources. In a real‚Äêworld scenario you would fine-tune on the full SST-2 dataset (‚âà67 000 examples), use more epochs, larger batches, and (ideally) GPU acceleration to achieve much higher accuracy.\n",
    "\n",
    "**Steps:**\n",
    "1. **Specify your sentences**  \n",
    "   At the very top of the cell, replace or extend the entries in the `sentences` list:\n",
    "   ```python\n",
    "   sentences = [\n",
    "       \"I enjoyed this product!\",\n",
    "       \"Really awful experience.\",\n",
    "       \"Your custom sentence here.\"\n",
    "   ]\n",
    "Load the fine-tuned model\n",
    "The code will automatically load the tokenizer and model from the distilbert_finetuned/ directory where our toy classifier is saved.\n",
    "\n",
    "Tokenise & Infer\n",
    "Each sentence is tokenised (max length 64), converted to PyTorch tensors, and fed into the model in evaluation mode.\n",
    "\n",
    "Map predictions to labels\n",
    "The numeric outputs (0 or 1) are mapped back to human-readable labels (\"negative\" or \"positive\") and printed.\n",
    "\n",
    "2. Interactive Sentiment Inference Using a Pre-Trained SST-2 Model\n",
    "This cell lets you classify any English sentences as POSITIVE or NEGATIVE using Hugging Face‚Äôs official DistilBERT checkpoint fine-tuned on the full SST-2 dataset.\n",
    "\n",
    "Steps:\n",
    "\n",
    "Specify your sentences\n",
    "At the top of the cell, edit the examples list with any sentences you want to evaluate:\n",
    "\n",
    "examples = [\n",
    "    \"I don't understand why people even buy this.\",\n",
    "    \"Really awful experience.\",\n",
    "    \"The product is excellent‚Äîhighly recommended\"\n",
    "    # Add your custom sentences here.\n",
    "]\n",
    "\n",
    "Load the official SST-2 model\n",
    "The code uses the checkpoint distilbert-base-uncased-fine¬≠tuned-sst-2-english.\n",
    "\n",
    "Tokenise & Infer\n",
    "Sentences are tokenised to max length 64, converted to tensors, and passed into the model in evaluation mode.\n",
    "\n",
    "Print predictions\n",
    "Each input is printed alongside its predicted label (\"POSITIVE\" or \"NEGATIVE\").\n",
    "\n",
    "Feel free to experiment with both the toy and the official models. For production-grade performance, follow the fine-tuning pipeline on the full dataset as shown in the previous notebook.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26613814-51d1-46ca-ac12-af952092c433",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\IAGhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~arkupsafe'.\n",
      "  You can safely remove it manually.\n",
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\IAGhe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\~orch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "jupyterlab 4.2.4 requires httpx>=0.25.0, but you have httpx 0.13.3 which is incompatible.\n",
      "torchvision 0.22.0 requires torch==2.7.0, but you have torch 2.7.1+cpu which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet --upgrade --force-reinstall torch --index-url https://download.pytorch.org/whl/cpu\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b1c43e-eca3-4646-a4de-836215c14ebb",
   "metadata": {},
   "source": [
    "Thought for a couple of seconds\n",
    "\n",
    "```markdown\n",
    "## Interactive Inference with Our Toy DistilBERT Model\n",
    "\n",
    "Use the cell below to classify your own sentences as **positive** or **negative**. Simply edit the `sentences` list at the top with the text you want to evaluate.\n",
    "\n",
    "> **Note:** This is a **toy model** trained on only 40 examples due to limited compute resources. In a real‚Äêworld scenario you would fine-tune on the full SST-2 dataset (‚âà67k examples), use more epochs, larger batches, and (ideally) GPU acceleration to achieve much higher accuracy.\n",
    "\n",
    "---\n",
    "\n",
    "1. **Specify your sentences**  \n",
    "   At the very top of the cell, replace or extend the entries in the `sentences` list:\n",
    "   ```python\n",
    "   sentences = [\n",
    "       \"I enjoyed this product!\",\n",
    "       \"Really awful experience.\",\n",
    "       \"Your custom sentence here.\"\n",
    "   ]\n",
    "   ```\n",
    "\n",
    "2. **Load the fine-tuned model**  \n",
    "   The code will automatically load the tokenizer and model from the `distilbert_finetuned/` directory where our toy classifier is saved.\n",
    "\n",
    "3. **Tokenise & Infer**  \n",
    "   Each sentence is tokenised (max length 64), converted to PyTorch tensors, and fed into the model in evaluation mode.\n",
    "\n",
    "4. **Map predictions to labels**  \n",
    "   The numeric outputs (`0` or `1`) are mapped back to human-readable labels (`\"negative\"` or `\"positive\"`) and printed.\n",
    "\n",
    "---\n",
    "\n",
    "Feel free to experiment with different sentences. If you need higher fidelity, follow the same pipeline but fine-tune on a larger dataset and adjust hyperparameters accordingly.  \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d489bf9-cb4b-4a8d-96a6-a800fbbb4665",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä£ \"I enjoyed this product!\" ‚Üí negative\n",
      "‚Ä£ \"Really awful experience.\" ‚Üí negative\n",
      "‚Ä£ \"Product is simply Excellent!\" ‚Üí negative\n"
     ]
    }
   ],
   "source": [
    "# 0) üëâ Enter your own sentences below to classify\n",
    "#    Replace or extend the list with any sentences you want the model to predict.\n",
    "sentences = [\n",
    "    \"I enjoyed this product!\",\n",
    "    \"Really awful experience.\",\n",
    "    \"Product is simply Excellent!\"\n",
    "    # Add more sentences here, e.g. \"Your custom sentence here.\"\n",
    "]\n",
    "\n",
    "# 1) Imports\n",
    "import torch\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizerFast\n",
    "\n",
    "# 2) Point to your fine-tuned model directory\n",
    "model_path = r\"C:\\Users\\IAGhe\\OneDrive\\Documents\\Learning\\portfolio\\toy_transformer_sentiment\\Model\\distilbert_finetuned\"\n",
    "\n",
    "# 3) Load tokenizer & model\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(model_path)\n",
    "model     = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "model.eval()   # set to evaluation mode\n",
    "\n",
    "# 4) Tokenise and convert to tensors\n",
    "inputs = tokenizer(\n",
    "    sentences,\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=64,\n",
    "    return_tensors=\"pt\"\n",
    ")\n",
    "\n",
    "# 5) Run inference (CPU-only)\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "    preds  = logits.argmax(dim=-1).tolist()\n",
    "\n",
    "# 6) Map to human-readable labels and print results\n",
    "id2label = {0: \"negative\", 1: \"positive\"}\n",
    "results = [{\"sentence\": s, \"prediction\": id2label[p]} for s, p in zip(sentences, preds)]\n",
    "for r in results:\n",
    "    print(f\"‚Ä£ \\\"{r['sentence']}\\\" ‚Üí {r['prediction']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfbdd1b9-6feb-407d-93e6-913a51c7c984",
   "metadata": {},
   "source": [
    "## Interactive Sentiment Inference Using a Pre-Trained SST-2 Model\n",
    "\n",
    "This cell lets you classify any English sentences as **POSITIVE** or **NEGATIVE** using Hugging Face‚Äôs official DistilBERT checkpoint fine-tuned on SST-2.\n",
    "\n",
    "1. **Specify your sentences**\n",
    "   At the top, edit the `examples` list with any sentences you want to evaluate:\n",
    "\n",
    "   ```python\n",
    "   examples = [\n",
    "       \"I don't understand why people even buy this.\",\n",
    "       \"Really awful experience.\",\n",
    "       \"The product is excellent‚Äîhighly recommended\"\n",
    "       # Add your custom sentences here.\n",
    "   ]\n",
    "   ```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c216804e-5924-4441-ae06-dbb9615285ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "¬ª \"I don't understand why people even buy this.\" ‚Üí NEGATIVE\n",
      "¬ª \"Really awful experience.\" ‚Üí NEGATIVE\n",
      "¬ª \"The product is excellent‚Äîhighly recommended\" ‚Üí POSITIVE\n"
     ]
    }
   ],
   "source": [
    "# 0) üëâ Enter your own sentences below to classify\n",
    "#    Replace or extend this list with any sentences you want to evaluate.\n",
    "examples = [\n",
    "    \"I don't understand why people even buy this.\",\n",
    "    \"Really awful experience.\",\n",
    "    \"The product is excellent‚Äîhighly recommended\"\n",
    "    # e.g. \"Your custom sentence here.\"\n",
    "]\n",
    "\n",
    "# 1) Imports\n",
    "import torch\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
    "\n",
    "# 2) Load the official SST-2 fine-tuned DistilBERT model\n",
    "checkpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
    "tokenizer  = DistilBertTokenizerFast.from_pretrained(checkpoint)\n",
    "model      = DistilBertForSequenceClassification.from_pretrained(checkpoint)\n",
    "model.eval()\n",
    "\n",
    "# 3) Inference helper function\n",
    "def predict(sentences):\n",
    "    enc = tokenizer(\n",
    "        sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=64,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    with torch.no_grad():\n",
    "        logits = model(**enc).logits\n",
    "        preds  = logits.argmax(dim=-1).tolist()\n",
    "    return [model.config.id2label[p] for p in preds]\n",
    "\n",
    "# 4) Run predictions on your examples\n",
    "results = predict(examples)\n",
    "for sentence, label in zip(examples, results):\n",
    "    print(f\"¬ª \\\"{sentence}\\\" ‚Üí {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bc7a73-548e-4764-85a3-fed85afa909f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
